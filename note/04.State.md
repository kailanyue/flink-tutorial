

## 状态处理

## Keyed DataStream(键控状态)

1. 使用键控状态，需要在数据流上指定一个键，该键应该用于对状态进行分区。键控状态是根据输入数据流中定义的键（key）来维护和访问的。
2. Flink为每个键值维护一个状态实例，并将具有相同键的所有数据，都分区到同一个算子任务中，这个任务会维护和处理这个key对应的状态。当任务处理一条数据时，它会自动将状态的访问范围限定为当前数据的key。因此，具有相同key的所有数据都会访问相同的状态。
3. Keyed State很类似于一个分布式的key-value map数据结构，只能用于KeyedStream（keyBy算子处理之后）。               

Flink的Keyed State支持以下数据类型：

- ValueState[T]保存单个的值，值的类型为T。

  `get操作: ValueState.value()`

  `set操作: ValueState.update(value: T)`

- ListState[T]保存一个列表，列表里的元素的数据类型为T。基本操作如下：

  `ListState.add(value: T)`

  `ListState.addAll(values: java.util.List[T])`

  `ListState.get() 返回Iterable[T]`

  `ListState.update(values: java.util.List[T])MapState[K, V]保存Key-Value对。`

- `MapState.get(key: K)`

  `MapState.put(key: K, value: V)`

  `MapState.contains(key: K)`

  `MapState.remove(key: K)`

- `ReducingState[T]`

- `AggregatingState[I, O]`
- 所有类型的状态还有一个`clear()` 方法，清除当前 key 下的状态数据，也就是当前输入元素的 key。

状态通过 `RuntimeContext` 进行访问，因此只能在 *rich functions* 中使用。请参阅[这里](https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/user_defined_functions.html#rich-functions)获取相关信息， 但是我们很快也会看到一个例子。`RichFunction` 中 `RuntimeContext` 提供如下方法：

- `ValueState<T> getState(ValueStateDescriptor<T>)`
- `ReducingState<T> getReducingState(ReducingStateDescriptor<T>)`
- `ListState<T> getListState(ListStateDescriptor<T>)`
- `AggregatingState<IN, OUT> getAggregatingState(AggregatingStateDescriptor<IN, ACC, OUT>)`
- `MapState<UK, UV> getMapState(MapStateDescriptor<UK, UV>)`

#### ValueState

Java中的状态定义

1. transient声明的成员变量不参与序列化过程
2. 状态描述器的定义和初始化操作需要在 open 方法中完成
3. 当状态的类型不是基本类型的时候，Descriptor 的 Typeinfo要使用 `TypeInformation.of(new TypeHint<List<String>>() { })`

```java
keyed.map(new RichMapFunction<Tuple2<String, Integer>, Tuple2<String, Integer>>() {

    // transient声明一个实例变量，当对象存储时，它的值不需要维持,用transient关键字标记的成员变量不参与序列化过程。
    private transient ValueState<Integer> counter;

    @Override
    public void open(Configuration parameters) throws Exception {

        // 先定义一个状态描述器(State的类型，名称)，此处不需要管理key只需要管理
        ValueStateDescriptor<Integer> stateDescriptor = new ValueStateDescriptor<>("wc", Integer.class);
        // 初始化或恢复历史状态
        counter = getRuntimeContext().getState(stateDescriptor);
    }

    @Override
    public Tuple2<String, Integer> map(Tuple2<String, Integer> input) throws Exception {
       // ... 
    }
}).print();
```

Scala 中的状态定义

1.  scala 中的状态可以使用 lazy初始化，也可以使用 open初始化，使用open的时候和 Java 写法一样
2. 同 Java 一样，类型为非基本类型的时候，Descriptor 的 Typeinfo要使用 `TypeInformation.of(classOf[ListBuffer[String]])`

```scala
// 使用 lazy 初始化义状态
lazy private val counter: ValueState[Int] =
	getRuntimeContext.getState(new ValueStateDescriptor[Int]("state", classOf[Int]))
// 使用 open 初始化状态
var listState: ValueState[ListBuffer[String]] = _
override def open(parameters: Configuration): Unit = {
    // 注意非基本类型要使用  TypeInformation.of(classOf[ListBuffer[String]])
    val stateDescriptor: ValueStateDescriptor[ListBuffer[String]] = new      	ValueStateDescriptor[ListBuffer[String]]("wc", TypeInformation.of(classOf[ListBuffer[String]]))
    listState = getRuntimeContext.getState(stateDescriptor)
}
```

#### ListState

```java
keyedStream.process(new KeyedProcessFunction<String, Tuple2<String, String>, Tuple2<String, List<String>>>() { 
    private transient ListState<String> listState;

    @Override
    public void open(Configuration parameters) throws Exception {
        ListStateDescriptor<String> listStateDescriptor = new ListStateDescriptor<>("listState", String.class);
        listState = getRuntimeContext().getListState(listStateDescriptor);

    }

    @Override
    public void processElement(Tuple2<String, String> value, Context ctx, Collector<Tuple2<String, List<String>>> out) throws Exception {
        //...
    }
}).print();

ValueStateDescriptor<List<String>> stateDescriptor =
    new ValueStateDescriptor<>("wc", TypeInformation.of(new TypeHint<List<String>>() {
    }));
```



#### MapState

```java
private transient MapState<String, Double> mapState; //不参与序列化，不使用序列化赋值

@Override
public void open(Configuration parameters) throws Exception {
    MapStateDescriptor<String, Double> kvstate = new MapStateDescriptor<>("kvstate", String.class, Double.class);
    mapState = getRuntimeContext().getMapState(kvstate);
}
```



#### 状态有效期 (TTL)

任何类型的 keyed state 都可以有 有效期 (TTL)，如果配置了 TTL 且状态值已过期，则会尽最大可能清除对应的值，也就是状态有其存活时间。

```java
private transient ValueState<Integer> counter;

@Override
public void open(Configuration parameters) throws Exception {
    // 定义一个状态TTLConfig
    StateTtlConfig ttlConfig = StateTtlConfig.newBuilder(Time.seconds(10)) // 时间是分不同的keyed的
        .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)
        .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)
        .build();

    ValueStateDescriptor<Integer> stateDescriptor = new ValueStateDescriptor<>("wc", Integer.class);
    stateDescriptor.enableTimeToLive(ttlConfig);
    counter = getRuntimeContext().getState(stateDescriptor);
}
```

1.  `newBuilder` 的第一个参数表示数据的有效期，是必选项。

2. TTL 的更新策略（默认是 `OnCreateAndWrite`）：
    - `StateTtlConfig.UpdateType.OnCreateAndWrite` - 仅在创建和写入时更新
    - `StateTtlConfig.UpdateType.OnReadAndWrite` - 读取时也更新

3. 数据在过期但还未被清理时的可见性配置如下（默认为 `NeverReturnExpired`):
    - `StateTtlConfig.StateVisibility.NeverReturnExpired` - 不返回过期数据
    - `StateTtlConfig.StateVisibility.ReturnExpiredIfNotCleanedUp` - 会返回过期但未清理的数据

`NeverReturnExpired` 情况下，过期数据就像不存在一样，不管是否被物理删除。这对于不能访问过期数据的场景下非常有用，比如敏感数据。 `ReturnExpiredIfNotCleanedUp` 在数据被物理删除前都会返回。

##### 过期数据的清理

默认情况下，过期数据会在读取的时候被删除，例如 `ValueState#value`，同时会有后台线程定期清理（如果 StateBackend 支持的话）。可以通过 `StateTtlConfig` 配置关闭后台清理：

```java
StateTtlConfig ttlConfig = StateTtlConfig
    .newBuilder(Time.seconds(1))
    .disableCleanupInBackground() // 关闭后台清理
    .build();
```

##### 全量快照时进行清理

另外，你可以启用全量快照时进行清理的策略，这可以减少整个快照的大小。当前实现中不会清理本地的状态，但从上次快照恢复时，不会恢复那些已经删除的过期数据。 该策略可以通过 `StateTtlConfig` 配置进行配置：

```java
StateTtlConfig ttlConfig = StateTtlConfig
    .newBuilder(Time.seconds(1))
    .cleanupFullSnapshot()
    .build();
```

> 这种策略在 `RocksDBStateBackend` 的增量 checkpoint 模式下无效。

可以选择增量式清理状态数据，在状态访问或/和处理时进行。如果某个状态开启了该清理策略，则会在存储后端保留一个所有状态的惰性全局迭代器。 每次触发增量清理时，从迭代器中选择已经过期的数进行清理。

第一个参数：每次清理时检查状态的条目数，在每个状态访问时触发。

第二个参数：表示是否在处理每条记录时触发清理。 Heap backend 默认会检查 5 条状态，并且关闭在每条记录时触发清理。

```java
StateTtlConfig ttlConfig = StateTtlConfig
    .newBuilder(Time.seconds(1))
    .cleanupIncrementally(10, true)
    .build();
```



### Operator State

算子状态的作用范围限定为算子任务。这意味着由同一并行任务所处理的所有数据都可以访问到相同的状态，状态对于同一任务而言是共享的。算子状态不能由相同或不同算子的另一个任务访问。

Flink为算子状态提供三种基本数据结构：

- 列表状态（List state）：将状态表示为一组数据的列表。

- 联合列表状态（Union list state）：也将状态表示为数据的列表。它与常规列表状态的区别在于，在发生故障时，或者从保存点（savepoint）启动应用程序时如何恢复。

- 广播状态（Broadcast state）：如果一个算子有多项任务，而它的每项任务状态又都相同，那么这种特殊情况最适合应用广播状态。

### Broadcast State

官方文档：[Apache Flink 1.12 Documentation: Broadcast State 模式](https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/state/broadcast_state.html)

广播状态是一种特殊类型的操作符状态。引入它是为了支持一个流的记录需要被广播到所有下游任务的用例，在这些用例中，它们被用来在所有子任务中维护相同的状态。然后可以在处理第二个流的记录时访问这个状态。

示例：使用 BroadcastState 将事实表和维度表进行连接操作

[Java代码](../java/src/main/java/com/ngt/state/BroadcastStateDemo.java)
[Scala代码](../scala/src/main/scala/com/ngt/state/BroadcastStateDemo.java)

 broadcast state 的重要注意事项，在使用它时需要时刻清楚：

- **没有跨 task 通讯：**如上所述，这就是为什么**只有**在 `(Keyed)-BroadcastProcessFunction` 中处理广播流元素的方法里可以更改 broadcast state 的内容。 同时，用户需要保证所有 task 对于 broadcast state 的处理方式是一致的，否则会造成不同 task 读取 broadcast state 时内容不一致的情况，最终导致结果不一致。
- **broadcast state 在不同的 task 的事件顺序可能是不同的：**虽然广播流中元素的过程能够保证所有的下游 task 全部能够收到，但在不同 task 中元素的到达顺序可能不同。 所以 broadcast state 的更新*不能依赖于流中元素到达的顺序*。
- **所有的 task 均会对 broadcast state 进行 checkpoint：**虽然所有 task 中的 broadcast state 是一致的，但当 checkpoint 来临时所有 task 均会对 broadcast state 做 checkpoint。 这个设计是为了防止在作业恢复后读文件造成的文件热点。当然这种方式会造成 checkpoint 一定程度的写放大，放大倍数为 p（=并行度）。Flink 会保证在恢复状态/改变并发的时候数据**没有重复**且**没有缺失**。 在作业恢复时，如果与之前具有相同或更小的并发度，所有的 task 读取之前已经 checkpoint 过的 state。在增大并发的情况下，task 会读取本身的 state，多出来的并发（`p_new` - `p_old`）会使用轮询调度算法读取之前 task 的 state。
- **不使用 RocksDB state backend：** broadcast state 在运行时保存在内存中，需要保证内存充足。这一特性同样适用于所有其他 Operator State。



## Queryable State

官方文档 [Apache Flink 1.12 Documentation: Queryable State](https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/state/queryable_state.html)

将 Flink 的 managed keyed (partitioned) state 暴露给外部，从而用户可以在 Flink 外部查询作业 state。 在某些场景中，Queryable State 消除了对外部系统的分布式操作以及事务的需求，比如 KV 存储系统，而这些外部系统往往会成为瓶颈。除此之外，这个特性对于调试作业非常有用

进行查询时，state 会在并发线程中被访问，但 state 不会进行同步和拷贝。这种设计是为了避免同步和拷贝带来的作业延时。



### 架构

主要包括以下三部分:

1. `QueryableStateClient`，默认运行在 Flink 集群外部，负责提交用户的查询请求；
2. `QueryableStateClientProxy`，运行在每个 `TaskManager` 上(*即* Flink 集群内部)，负责接收客户端的查询请求，从所负责的 Task Manager 获取请求的 state，并返回给客户端；
3. `QueryableStateServer`, 运行在 `TaskManager` 上，负责服务本地存储的 state。

### 激活 Queryable State

为了在 Flink 集群上使用 queryable state，需要进行以下操作：

1. 将 `flink-queryable-state-runtime_2.11-1.12.0.jar` 从 [Flink distribution](https://flink.apache.org/downloads.html) 的 `opt/` 目录拷贝到 `lib/` 目录；
2. 将参数 `queryable-state.enable` 设置为 `true`。详细信息以及其它配置可参考文档 [Configuration](https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/deployment/config.html#queryable-state)。

为了验证集群的 queryable state 已经被激活，可以检查任意 task manager 的日志中是否包含 “Started the Queryable State Proxy Server @ …“。

### 将 state 设置为可查询的

激活集群的 queryable state 功能后，还要将 state 设置为可查询的才能对外可见，可以通过以下两种方式进行设置：

- 创建 `QueryableStateStream`，它会作为一个 sink，并将输入数据转化为 queryable state；
- 通过 `stateDescriptor.setQueryable(String queryableStateName)` 将 state 描述符所表示的 keyed state 设置成可查询的。

```java
// 服务端
stateDescriptor.setQueryable("my-query-name");

// 客户端查询
QueryableStateClient client = new QueryableStateClient("localhost", 9069);

CompletableFuture<ValueState<Integer>> future = client.getKvState(
    JobID.fromHexString("31081677fbc9fe700ca7d5c881abc709"),  // jobId
    "my-query-name",
    "flink",
    BasicTypeInfo.STRING_TYPE_INFO,
    stateDescriptor);
```



